# RAG System - Greenpeace Documents

Un sistema completo de Retrieval-Augmented Generation (RAG) especializado en documentos de Greenpeace, desarrollado como parte del curso de LLMs del ITBA.

## ðŸŒ DescripciÃ³n

Este proyecto proporciona un sistema RAG completo para hacer preguntas y obtener respuestas basadas en documentos de Greenpeace. El sistema incluye:

- **Chunking**: MÃºltiples estrategias para fragmentar documentos
- **Embedding**: GeneraciÃ³n de embeddings usando modelos de sentence-transformers
- **RecuperaciÃ³n**: BÃºsqueda semÃ¡ntica de documentos relevantes
- **GeneraciÃ³n**: Respuestas basadas en contexto usando LLMs locales (Ollama)
- **EvaluaciÃ³n**: MÃ©tricas completas para evaluar el rendimiento del sistema

## ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ greenpeace_rag/          # Paquete principal del sistema RAG
â”‚   â”œâ”€â”€ core/                # Funcionalidades principales
â”‚   â”œâ”€â”€ evaluation/          # Sistema de evaluaciÃ³n
â”‚   â”œâ”€â”€ models/              # ConfiguraciÃ³n de modelos
â”‚   â”œâ”€â”€ prompts/             # Prompts del sistema
â”‚   â”œâ”€â”€ schemas/             # Modelos Pydantic
â”‚   â”œâ”€â”€ utils/               # Utilidades compartidas
â”‚   â””â”€â”€ examples/            # Ejemplos de uso
â”œâ”€â”€ docs/                    # Documentos fuente (PDFs, MDs)
â”œâ”€â”€ docs_load_txt/           # Documentos procesados en formato TXT
â”œâ”€â”€ chroma_db/               # Base de datos vectorial (ChromaDB)
â”œâ”€â”€ clases/                  # Material del curso
â””â”€â”€ pyproject.toml           # ConfiguraciÃ³n del proyecto
```

## ðŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.11+
- [Ollama](https://ollama.ai/) instalado y ejecutÃ¡ndose
- Modelo `llama3.1:8b` descargado en Ollama

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/sendykuriel/rag_system.git
cd rag_system
```

2. **Crear y activar un entorno virtual:**
```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
```

3. **Instalar dependencias:**
```bash
pip install -e .
```

4. **Iniciar Ollama (en una terminal separada):**
```bash
ollama serve
```

5. **Descargar el modelo LLM (en otra terminal):**
```bash
ollama pull llama3.1:8b
```

## ðŸ“– Uso BÃ¡sico

### Ejemplo Simple

```python
from greenpeace_rag import GreenpeaceRAG

# Crear instancia del sistema RAG
rag = GreenpeaceRAG(
    chunk_strategy="recursive_characters",
    chunk_params={"chunk_char_size": 700, "chunk_overlap": 200}
)

# Configurar el sistema
rag.rag_setup()

# Hacer una pregunta
answer, context, docs = rag.generate_answers("Â¿QuÃ© es el cambio climÃ¡tico?")
print(answer)
```

### Ejecutar Ejemplos

El proyecto incluye varios ejemplos en `greenpeace_rag/examples/`:

```bash
# Ejemplo bÃ¡sico
python greenpeace_rag/examples/basic_usage.py

# Ejemplo de evaluaciÃ³n
python greenpeace_rag/examples/evaluation_example.py
```

## ðŸ”§ ConfiguraciÃ³n

### Estrategias de Chunking

- **`characters`**: FragmentaciÃ³n simple por caracteres
- **`recursive_characters`**: FragmentaciÃ³n recursiva (recomendado)
- **`documents_type`**: AdaptaciÃ³n segÃºn el tipo de documento

### Modelos Soportados

- **LLM**: Ollama con `llama3.1:8b` (por defecto)
- **Embeddings**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (por defecto)

## ðŸ“Š EvaluaciÃ³n

El sistema incluye un mÃ³dulo completo de evaluaciÃ³n con las siguientes mÃ©tricas:

- **Correctness**: PrecisiÃ³n de las respuestas generadas
- **Relevance**: Relevancia de las respuestas a las preguntas
- **Groundness**: Base de las respuestas en los documentos
- **Retrieval Relevance**: Relevancia de los documentos recuperados

Ver `greenpeace_rag/examples/evaluation_example.py` para mÃ¡s detalles.

## ðŸ› ï¸ Desarrollo

Este proyecto estÃ¡ estructurado de forma modular para facilitar:

- **Mantenimiento**: Cada mÃ³dulo tiene una responsabilidad especÃ­fica
- **Extensibilidad**: FÃ¡cil agregar nuevas funcionalidades
- **Testing**: Componentes independientes
- **ReutilizaciÃ³n**: Componentes pueden usarse por separado

## ðŸ“‹ Requisitos

- Python >= 3.11
- Ollama instalado y ejecutÃ¡ndose
- Modelo `llama3.1:8b` descargado
- Dependencias listadas en `pyproject.toml`

## ðŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de LangChain](https://python.langchain.com/)
- [Ollama](https://ollama.ai/)
- [Sentence Transformers](https://www.sbert.net/)
- [ChromaDB](https://www.trychroma.com/)

## ðŸ“„ Licencia

Este proyecto es parte del curso de LLMs del ITBA.

## ðŸ‘¤ Autor

Uriel Sendyk

